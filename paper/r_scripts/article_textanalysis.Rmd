---
title: "article_textanalysis"
author: "Jonas Paul Schoene"
date: "4/1/2021"
output: html_document
---

### Library/GGplot default settings/Clean Env

```{r}
library(tidyverse)
library(tidytext)
library(ggplot2)
library(topicmodels)
library(tm)
library(wordcloud)
library(textmineR)
library(textstem)
library(lmerTest)
library(Rmisc)
library(lme4)
library(lmerTest)
library(VGAM)
library(MuMIn)

options(scipen = 999)

theme_set(theme_bw())

rm(list = ls()) #Cleaning the R Environment, since the datasets are pretty big and can slow down the PC 
```

## Same-Sex Topic Modelling and Content Analysis 

```{r}
d <- read.csv("data_textanalysis/same_sex_tweets_for_textanalsis.csv")

head(d)

most_viral <- d %>% 
  dplyr::filter(!is.na(tweet_body)) %>% 
  dplyr::mutate(emotion_category = ifelse(valence > 1, "positive",ifelse(valence < -1, "negative", "neutral"))) %>% 
  dplyr::filter(emotion_category == "negative") %>% 
  top_n(20, retweets) %>% 
  dplyr::select(retweets, tweet_body, valence) %>% 
  arrange(retweets)

most_viral
```


# 1 GRAMS

```{r}
d <- read.csv("data_textanalysis/same_sex_tweets_for_textanalsis.csv")

head(d)

d <- d %>% 
  filter(!is.na(tweet_body))

tidy_d <- d %>%
  dplyr::group_by(valence) %>% 
  dplyr::select(tweet_body_lemmatized) %>% 
  unnest_tokens(word, tweet_body_lemmatized)

# Removing Stopwords ;;;;;;;;;;;

data(stop_words)

twitter_stopwords <- data.frame("word" = c("rt", "https","http","tco","â","ï", "º","lâ","lovewins","loveislove"))

twitter_stopwords$lexicon <- "gay_marriage"

stop_words_extended <- rbind(stop_words,twitter_stopwords)

tidy_d <- tidy_d %>% 
  group_by(valence) %>% 
  dplyr::anti_join(stop_words_extended ,by = c("word" = "word"))

# DTM Format ;;;;;;;;;;;;;;;;;;;;

tidy_d <- tidy_d %>% 
  group_by(word, valence) %>% 
  dplyr::summarise(count = n()) %>% 
  ungroup()

tidy_d$topic <- ifelse(tidy_d$valence > 1, "positive",ifelse(tidy_d$valence < -1, "negative", "neutral"))

tidy_d <- tidy_d %>% 
  filter(topic != "neutral") %>% 
  droplevels()

gay_dtm <- tidy_d %>%
  dplyr::filter(count > 1000 & is.na(word) == FALSE) %>% 
  dplyr::select(topic, word,count) %>% 
  cast_dtm(topic, word,count) 
  

# Topic Modell ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

## Perplexity ;;;;;;;;;;;;;;;;;;;

ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 3, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 4, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 200, control = list(seed = 1234))

perplexity(ap_lda)

# set a seed so that the output of the model is predictable
ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))
ap_lda

# Vizualisation Topics in the Tweets ;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  filter(!is.na(term)) %>% 
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()

beta_spread <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .0001 | topic2 > .0001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_spread

pd <- beta_spread
pd1 <- pd %>% 
  top_n(-10, log_ratio)
pd2 <- pd %>% 
  top_n(10, log_ratio)
pd <- rbind(pd1,pd2)
  
  
pd %>%  
  ggplot(., aes(x = reorder (term, log_ratio), y = log_ratio)) +
  geom_bar(stat = "identity") +
  coord_flip()+ 
  scale_x_reordered()

# Which Topics are in which emotion ;;;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_emotions <- tidy(ap_lda, matrix = "gamma")
ap_emotions

tidy(gay_dtm) %>%
  filter(document == "negative") %>%
  arrange(desc(count))

# reorder titles in order of topic 1, topic 2, etc before plotting
ap_emotions %>%
  mutate(title = reorder(document, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ document)

# Word Clouds ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

# People love word clouds so there you have it

# Word cloud for frequency (in percent)
wordcloud(words = beta_spread$term, freq = beta_spread$topic1 * 100, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

# Word cloud for uniqueness
wordcloud(words = pd$term, freq = pd$log_ratio, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

wordcloud(words = pd$term, freq = pd$log_ratio * -1, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```

# Bigrams

```{r}
d <- read.csv("data_textanalysis/same_sex_tweets_for_textanalsis.csv")

head(d)

d <- d %>% 
  filter(!is.na(tweet_body))

tidy_d <- d %>%
  dplyr::group_by(valence) %>% 
  dplyr::select(tweet_body_lemmatized) %>% 
  unnest_tokens(bigrams, tweet_body_lemmatized, token="ngrams", n=2)

# Removing Stopwords ;;;;;;;;;;;

data(stop_words)

twitter_stopwords <- data.frame("word" = c("rt", "https","http","tco","â","ï", "º","lâ","lovewins","loveislove"))

twitter_stopwords$lexicon <- "gay_marriage"

stop_words_extended <- rbind(stop_words,twitter_stopwords)

tidy_d <-  tidy_d %>%
    tidyr::separate(bigrams, c("word1", "word2"),
                    sep = " ", extra = "drop", fill = "right") %>%
    dplyr::filter(!word1 %in% stop_words_extended$word,
                  !word2 %in% stop_words_extended$word,
                  !is.na(word2)) %>%
    tidyr::unite(bigrams, word1, word2, sep = " ")

# DTM Format ;;;;;;;;;;;;;;;;;;;;

tidy_d <- tidy_d %>% 
  group_by(bigrams, valence) %>% 
  dplyr::summarise(count = n()) %>% 
  ungroup()

tidy_d$topic <- ifelse(tidy_d$valence > 1, "positive",ifelse(tidy_d$valence < -1, "negative", "neutral"))

tidy_d <- tidy_d %>% 
  filter(topic != "neutral") %>% 
  droplevels()

gay_dtm <- tidy_d %>% 
  filter(count > 2 & (is.na(bigrams) == FALSE)) %>% #remove rare words and empty rows
  dplyr::select(topic, bigrams,count) %>% 
  cast_dtm(topic, bigrams,count) 
  

# Topic Modell ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

## Perplexity ;;;;;;;;;;;;;;;;;;;

ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 3, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 4, control = list(seed = 1234))

perplexity(ap_lda)

#ap_lda <- LDA(gay_dtm, k = 200, control = list(seed = 1234))

perplexity(ap_lda)

# set a seed so that the output of the model is predictable
ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))
ap_lda

# Vizualisation Topics in the Tweets ;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  filter(!is.na(term)) %>% 
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()

beta_spread <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .0001 | topic2 > .0001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_spread

pd <- beta_spread
pd1 <- pd %>% 
  top_n(-10, log_ratio)
pd2 <- pd %>% 
  top_n(10, log_ratio)
pd <- rbind(pd1,pd2)
  
  
pd %>%  
  ggplot(., aes(x = reorder (term, log_ratio), y = log_ratio)) +
  geom_bar(stat = "identity") +
  coord_flip()+ 
  scale_x_reordered()

# Which Topics are in which emotion ;;;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_emotions <- tidy(ap_lda, matrix = "gamma")
ap_emotions

tidy(gay_dtm) %>%
  filter(document == "negative") %>%
  arrange(desc(count))

# reorder titles in order of topic 1, topic 2, etc before plotting
ap_emotions %>%
  mutate(title = reorder(document, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ document)

# Word Clouds ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

# People love word clouds so there you have it

# Word cloud for frequency (in percent)
wordcloud(words = beta_spread$term, freq = beta_spread$topic1 * 100, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

# Word cloud for uniqueness
wordcloud(words = pd$term, freq = pd$log_ratio, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

wordcloud(words = pd$term, freq = pd$log_ratio * -1, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```
# Positive Language == positive Emotion

```{r}
df_g <- read.csv("data_textanalysis/same_sex_tweets_for_textanalsis.csv")

df_g <- df_g %>% 
  filter(!is.na(tweet_body))

df_g <- df_g %>% 
  filter(!(grepl("cry|tear|scream|sob|cried", df_g$tweet_body_lemmatized)))

df_g$retweets_reciprocal <- 1 - reciprocal(df_g$retweets + 1)
df_g$followers_log <- log(df_g$followers + 1)
df_g$sen_neg <- abs(df_g$sen_neg)

# Same-Sex
model1 = lmer(retweets_reciprocal ~  sen_pos + sen_neg + sen_pos:sen_neg + scale(followers_log) + (1|user_id), df_g); summary(model1)

r.squaredGLMM(model1)

confint.merMod(model1,level = 0.95, method = "boot", boot.type = "perc", nsim = 100, oldNames = F)
```


## Trump Win Topic Modelling and Content Analysis 

```{r}
d <- read.csv("data_textanalysis/trump_tweets_for_textanalsis.csv")

most_viral <- d %>% 
  dplyr::filter(!is.na(tweet_body)) %>% 
  dplyr::mutate(emotion_category = ifelse(valence > 1, "positive",ifelse(valence < -1, "negative", "neutral"))) %>% 
  dplyr::filter(emotion_category == "negative") %>% 
  top_n(20, retweets) %>% 
  dplyr::select(retweets, tweet_body, valence) %>% 
  arrange(retweets)

most_viral
``` 
# 1 GRAMS

```{r}
d <- read.csv("data_textanalysis/trump_tweets_for_textanalsis.csv")

head(d)

tidy_d <- d %>%
  group_by(valence) %>% 
  select(tweet_body_lemmatized) %>% 
  unnest_tokens(word, tweet_body_lemmatized)

# Removing Stopwords ;;;;;;;;;;;

data(stop_words)

twitter_stopwords <- data.frame("word" = c("rt", "https","http","tco","â","ï", "º","lâ","lovewins","loveislove"))

twitter_stopwords$lexicon <- "gay_marriage"

stop_words_extended <- rbind(stop_words,twitter_stopwords)

tidy_d <- tidy_d %>% 
  group_by(valence) %>% 
  dplyr::anti_join(stop_words_extended ,by = c("word" = "word"))

# DTM Format ;;;;;;;;;;;;;;;;;;;;

tidy_d <- tidy_d %>% 
  group_by(word, valence) %>% 
  dplyr::summarise(count = n()) %>% 
  ungroup()

tidy_d$topic <- ifelse(tidy_d$valence > 1, "positive",ifelse(tidy_d$valence < -1, "negative", "neutral"))

tidy_d <- tidy_d %>% 
  filter(topic != "neutral") %>% 
  droplevels()

gay_dtm <- tidy_d %>%
  filter(count > 1000 & is.na(word) == FALSE) %>% 
  select(topic, word,count) %>% 
  cast_dtm(topic, word,count) 
  

# Topic Modell ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

## Perplexity ;;;;;;;;;;;;;;;;;;;

ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 3, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 4, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 200, control = list(seed = 1234))

perplexity(ap_lda)

# set a seed so that the output of the model is predictable
ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))
ap_lda

# Vizualisation Topics in the Tweets ;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  filter(!is.na(term)) %>% 
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()

beta_spread <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .0001 | topic2 > .0001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_spread

pd <- beta_spread
pd1 <- pd %>% 
  top_n(-10, log_ratio)
pd2 <- pd %>% 
  top_n(10, log_ratio)
pd <- rbind(pd1,pd2)
  
  
pd %>%  
  ggplot(., aes(x = reorder (term, log_ratio), y = log_ratio)) +
  geom_bar(stat = "identity") +
  coord_flip()+ 
  scale_x_reordered()

# Which Topics are in which emotion ;;;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_emotions <- tidy(ap_lda, matrix = "gamma")
ap_emotions

tidy(gay_dtm) %>%
  filter(document == "negative") %>%
  arrange(desc(count))

# reorder titles in order of topic 1, topic 2, etc before plotting
ap_emotions %>%
  mutate(title = reorder(document, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ document)

# Word Clouds ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

# People love word clouds so there you have it

# Word cloud for frequency (in percent)
wordcloud(words = beta_spread$term, freq = beta_spread$topic1 * 100, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

# Word cloud for uniqueness
wordcloud(words = pd$term, freq = pd$log_ratio, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

wordcloud(words = pd$term, freq = pd$log_ratio * -1, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```

# Bigrams

```{r}
d <- read.csv("data_textanalysis/trump_tweets_for_textanalsis.csv")

head(d)

tidy_d <- d %>%
  group_by(valence) %>% 
  select(tweet_body_lemmatized) %>% 
  unnest_tokens(bigrams, tweet_body_lemmatized, token="ngrams", n=2)

# Removing Stopwords ;;;;;;;;;;;

data(stop_words)

twitter_stopwords <- data.frame("word" = c("rt", "https","http","tco","â","ï", "º","lâ"))

twitter_stopwords$lexicon <- "gay_marriage"

stop_words_extended <- rbind(stop_words,twitter_stopwords)

tidy_d <-  tidy_d %>%
    tidyr::separate(bigrams, c("word1", "word2"),
                    sep = " ", extra = "drop", fill = "right") %>%
    dplyr::filter(!word1 %in% stop_words_extended$word,
                  !word2 %in% stop_words_extended$word,
                  !is.na(word2)) %>%
    tidyr::unite(bigrams, word1, word2, sep = " ")

# DTM Format ;;;;;;;;;;;;;;;;;;;;

tidy_d <- tidy_d %>% 
  group_by(bigrams, valence) %>% 
  dplyr::summarise(count = n()) %>% 
  ungroup()

tidy_d$topic <- ifelse(tidy_d$valence > 1, "positive",ifelse(tidy_d$valence < -1, "negative", "neutral"))

tidy_d <- tidy_d %>% 
  filter(topic != "neutral") %>% 
  droplevels()

gay_dtm <- tidy_d %>% 
  filter(count > 2 & (is.na(bigrams) == FALSE)) %>% #remove rare words and empty rows
  select(topic, bigrams,count) %>% 
  cast_dtm(topic, bigrams,count) 
  

# Topic Modell ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

## Perplexity ;;;;;;;;;;;;;;;;;;;

ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 3, control = list(seed = 1234))

perplexity(ap_lda)

ap_lda <- LDA(gay_dtm, k = 4, control = list(seed = 1234))

perplexity(ap_lda)

#ap_lda <- LDA(gay_dtm, k = 200, control = list(seed = 1234))

perplexity(ap_lda)

# set a seed so that the output of the model is predictable
ap_lda <- LDA(gay_dtm, k = 2, control = list(seed = 1234))
ap_lda

# Vizualisation Topics in the Tweets ;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics

ap_top_terms <- ap_topics %>%
  group_by(topic) %>%
  filter(!is.na(term)) %>% 
  top_n(10, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

ap_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()

beta_spread <- ap_topics %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .0001 | topic2 > .0001) %>%
  mutate(log_ratio = log2(topic2 / topic1))

beta_spread

pd <- beta_spread
pd1 <- pd %>% 
  top_n(-10, log_ratio)
pd2 <- pd %>% 
  top_n(10, log_ratio)
pd <- rbind(pd1,pd2)
  
  
pd %>%  
  ggplot(., aes(x = reorder (term, log_ratio), y = log_ratio)) +
  geom_bar(stat = "identity") +
  coord_flip()+ 
  scale_x_reordered()

# Which Topics are in which emotion ;;;;;;;;;;;;;;;;;;;;;;;;;;;;

ap_emotions <- tidy(ap_lda, matrix = "gamma")
ap_emotions

tidy(gay_dtm) %>%
  filter(document == "negative") %>%
  arrange(desc(count))

# reorder titles in order of topic 1, topic 2, etc before plotting
ap_emotions %>%
  mutate(title = reorder(document, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ document)

# Word Clouds ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

# People love word clouds so there you have it

# Word cloud for frequency (in percent)
wordcloud(words = beta_spread$term, freq = beta_spread$topic1 * 100, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

# Word cloud for uniqueness
wordcloud(words = pd$term, freq = pd$log_ratio, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

wordcloud(words = pd$term, freq = pd$log_ratio * -1, min.freq = 1,
          max.words=200, random.order=FALSE, rot.per=0.35, 
          colors=brewer.pal(8, "Dark2"))

```
